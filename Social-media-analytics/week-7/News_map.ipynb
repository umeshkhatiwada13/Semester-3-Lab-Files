{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204846c0-5311-4c85-825d-4af5927cf959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (4.9.2)\n",
      "Collecting folium\n",
      "  Downloading folium-0.17.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.5)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Downloading branca-0.7.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (1.24.4)\n",
      "Requirement already satisfied: xyzservices in c:\\programdata\\anaconda3\\lib\\site-packages (from folium) (2022.9.0)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Downloading folium-0.17.0-py2.py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.4 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/108.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.4/108.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.4/125.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading branca-0.7.2-py3-none-any.whl (25 kB)\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy, branca, folium\n",
      "Successfully installed branca-0.7.2 folium-0.17.0 geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 folium geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a47fc3a-6f5e-4f59-ba64-0efd2d5252fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cities  100\n",
      "City counts:\n",
      "Washington: 5 articles\n",
      "Nashville: 1 articles\n",
      "WASHINGTON: 1 articles\n",
      "Philadelphia: 1 articles\n",
      "New York: 1 articles\n",
      "Map generation complete. Check us_news_map.html for the map.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "keyword = 'Donald Trump'\n",
    "base_url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map centered on USA\n",
    "map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Function to fetch news and plot locations on map\n",
    "def fetch_and_plot_news(keyword, map):\n",
    "    try:\n",
    "        params = {\n",
    "            'q': keyword,\n",
    "            'apiKey': api_key,\n",
    "            'pageSize': 100,  # Fetch up to 100 articles\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            news_data = response.json()\n",
    "            if news_data.get('articles'):\n",
    "                city_counts = {}\n",
    "                print('Total cities ',len(news_data['articles']))\n",
    "                for article in news_data['articles']:\n",
    "                    city_name = extract_city_from_article(article)\n",
    "                    if city_name:\n",
    "                        if city_name in city_counts:\n",
    "                            city_counts[city_name] += 1\n",
    "                        else:\n",
    "                            city_counts[city_name] = 1\n",
    "                        \n",
    "                        location = geolocator.geocode(city_name)\n",
    "                        if location:\n",
    "                            # Add a small random offset to the latitude and longitude\n",
    "                            lat_offset = random.uniform(-1, 1)\n",
    "                            lon_offset = random.uniform(-1, 1)\n",
    "                            \n",
    "                            folium.Marker(\n",
    "                                [location.latitude + lat_offset, location.longitude + lon_offset],\n",
    "                                popup=f\"<b>{article['title']}</b><br>{article['description']}\"\n",
    "                            ).add_to(map)\n",
    "                \n",
    "                # Print city counts\n",
    "                print(\"City counts:\")\n",
    "                for city, count in city_counts.items():\n",
    "                    print(f\"{city}: {count} articles\")\n",
    "                \n",
    "                # Check for cities with no data\n",
    "                all_cities = set(city_counts.keys())\n",
    "                cities_with_data = set(city_counts.keys())\n",
    "                cities_with_no_data = all_cities - cities_with_data\n",
    "                if cities_with_no_data:\n",
    "                    print(\"Cities with no data:\")\n",
    "                    for city in cities_with_no_data:\n",
    "                        print(city)\n",
    "            else:\n",
    "                print(\"No articles found for the keyword.\")\n",
    "        else:\n",
    "            print(f\"Error fetching news. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or plotting news: {e}\")\n",
    "\n",
    "# Function to extract city from article content\n",
    "def extract_city_from_article(article):\n",
    "    try:\n",
    "        if 'content' in article and article['content']:\n",
    "            text = article['content']\n",
    "            # Regular expression pattern to find city names\n",
    "            city_pattern = r'\\b(?:New York|Los Angeles|Chicago|Houston|Phoenix|Philadelphia|San Antonio|San Diego|Dallas|San Jose|Austin|Jacksonville|Fort Worth|Columbus|San Francisco|Charlotte|Indianapolis|Seattle|Denver|Washington|Boston|El Paso|Nashville|Detroit|Oklahoma City|Portland|Las Vegas|Memphis|Louisville|Baltimore)\\b'\n",
    "            \n",
    "            # Find all cities in the text using the pattern\n",
    "            cities_found = re.findall(city_pattern, text, flags=re.IGNORECASE)\n",
    "            \n",
    "            if cities_found:\n",
    "                # Return the first city found (you can modify as needed for your use case)\n",
    "                return cities_found[0]\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting city from article: {e}\")\n",
    "        return None\n",
    "\n",
    "# Call the function to fetch and plot news\n",
    "fetch_and_plot_news(keyword, map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"us_news_map.html\")\n",
    "\n",
    "print(\"Map generation complete. Check us_news_map.html for the map.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
