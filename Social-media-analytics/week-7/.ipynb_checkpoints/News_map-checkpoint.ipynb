{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204846c0-5311-4c85-825d-4af5927cf959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (4.9.2)\n",
      "Collecting folium\n",
      "  Downloading folium-0.17.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.5)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Downloading branca-0.7.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (1.24.4)\n",
      "Requirement already satisfied: xyzservices in c:\\programdata\\anaconda3\\lib\\site-packages (from folium) (2022.9.0)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Downloading folium-0.17.0-py2.py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.4 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/108.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.4/108.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.4/125.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading branca-0.7.2-py3-none-any.whl (25 kB)\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy, branca, folium\n",
      "Successfully installed branca-0.7.2 folium-0.17.0 geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 folium geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61daacea-cb1c-4848-ba6e-d2f4451cba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[{'source': {'id': 'google-news', 'name': 'Google News'}, 'author': 'BBC.com', 'title': \"Drake's Toronto home 'The Embassy' hit by floods - BBC.com\", 'description': None, 'url': 'https://news.google.com/rss/articles/CBMiLGh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy92aWRlb3MvY3BkOTdwMzN5NGpv0gEA?oc=5', 'urlToImage': None, 'publishedAt': '2024-07-17T10:01:55Z', 'content': None}, {'source': {'id': 'google-news', 'name': 'Google News'}, 'author': 'CP24', 'title': 'Don Valley Parkway reopens after record-breaking rainfall, flooding in Toronto - CP24', 'description': None, 'url': 'https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LmNwMjQuY29tL25ld3MvZG9uLXZhbGxleS1wYXJrd2F5LXJlb3BlbnMtYWZ0ZXItcmVjb3JkLWJyZWFraW5nLXJhaW5mYWxsLWZsb29kaW5nLWluLXRvcm9udG8tMS42OTY2NzQ40gEA?oc=5', 'urlToImage': None, 'publishedAt': '2024-07-17T09:45:49Z', 'content': None}, {'source': {'id': 'google-news', 'name': 'Google News'}, 'author': 'TechRadar', 'title': 'All four rumored Google Pixel 9 models have been photographed by a regulatory agency - TechRadar', 'description': None, 'url': 'https://news.google.com/rss/articles/CBMiiQFodHRwczovL3d3dy50ZWNocmFkYXIuY29tL3Bob25lcy9nb29nbGUtcGl4ZWwtcGhvbmVzL2FsbC1mb3VyLXJ1bW9yZWQtZ29vZ2xlLXBpeGVsLTktbW9kZWxzLWhhdmUtYmVlbi1waG90b2dyYXBoZWQtYnktYS1yZWd1bGF0b3J5LWFnZW5jedIBAA?oc=5', 'urlToImage': None, 'publishedAt': '2024-07-17T09:17:23Z', 'content': None}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "url = f'https://newsapi.org/v2/top-headlines?country=ca&apiKey={api_key}'\n",
    "\n",
    "# Fetch news articles\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "print(len(data))\n",
    "\n",
    "articles = data['articles']\n",
    "\n",
    "print(articles[0:3])\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map\n",
    "map = folium.Map(location=[56.1304, -106.3468], zoom_start=4)  # Centered on Canada\n",
    "\n",
    "# Function to geocode and add markers to the map\n",
    "def add_marker(title, description, location):\n",
    "    try:\n",
    "        geocode_result = geolocator.geocode(location)\n",
    "        if geocode_result:\n",
    "            folium.Marker(\n",
    "                [geocode_result.latitude, geocode_result.longitude],\n",
    "                popup=f\"<b>{title}</b><br>{description}\"\n",
    "            ).add_to(map)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {location}: {e}\")\n",
    "\n",
    "# Loop through articles and plot them on the map\n",
    "for article in articles:\n",
    "    title = article['title']\n",
    "    description = article['description']\n",
    "    if article['source']['name']:  # Assuming source name is the location\n",
    "        location = article['source']['name']\n",
    "        add_marker(title, description, location)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"canada_news_map1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b6bbbf-9162-4ff6-9f96-7d5533884454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cdd962f-8cc2-45dd-b79d-2dedb0ee1bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: folium in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (0.17.0)\n",
      "Requirement already satisfied: geopy in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (0.7.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from folium) (1.24.4)\n",
      "Requirement already satisfied: xyzservices in c:\\programdata\\anaconda3\\lib\\site-packages (from folium) (2022.9.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests folium geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2280be61-70ee-40f5-8552-d3bb3820257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "keyword = 'Donald Trump'\n",
    "base_url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map\n",
    "map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)  # Centered on USA\n",
    "\n",
    "# Function to fetch news for a city\n",
    "def fetch_news(city):\n",
    "    params = {\n",
    "        'q': keyword,\n",
    "        'from': today,\n",
    "        'to': today,\n",
    "        'apiKey': api_key,\n",
    "        'pageSize': 5,  # Fetch 5 articles per city for brevity\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Function to add markers to the map\n",
    "def add_marker(title, description, city, map):\n",
    "    try:\n",
    "        location = geolocator.geocode(city)\n",
    "        if location:\n",
    "            folium.Marker(\n",
    "                [location.latitude, location.longitude],\n",
    "                popup=f\"<b>{title}</b><br>{description}\"\n",
    "            ).add_to(map)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {city}: {e}\")\n",
    "\n",
    "# Loop through cities and fetch news\n",
    "for city in cities:\n",
    "    news_data = fetch_news(city)\n",
    "    print(len(news_data))\n",
    "    if news_data.get('articles'):\n",
    "        for article in news_data['articles']:\n",
    "            title = article['title']\n",
    "            description = article['description'] if article['description'] else 'No description available'\n",
    "            add_marker(title, description, city, map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"us_news_map_1.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7723b933-727a-459a-9f5b-9b2227adcf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "Map generation complete. Check us_news_map.html for the map.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "keyword = 'Donald Trump'\n",
    "base_url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map centered on USA\n",
    "map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Function to fetch news for a city\n",
    "def fetch_news(city):\n",
    "    try:\n",
    "        params = {\n",
    "            'q': keyword,\n",
    "            'from': today,\n",
    "            'to': today,\n",
    "            'apiKey': api_key,\n",
    "            'pageSize': 5,  # Fetch 5 articles per city for brevity\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching news for {city}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news for {city}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to add markers to the map\n",
    "def add_marker(title, description, lat, lon, map):\n",
    "    try:\n",
    "        folium.Marker(\n",
    "            [lat, lon],\n",
    "            popup=f\"<b>{title}</b><br>{description}\"\n",
    "        ).add_to(map)\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding marker for {title}: {e}\")\n",
    "\n",
    "# Loop through cities and fetch news\n",
    "for city in cities:\n",
    "    news_data = fetch_news(city)\n",
    "    print(news_data)\n",
    "    if news_data and news_data.get('articles'):\n",
    "        for article in news_data['articles']:\n",
    "            title = article['title']\n",
    "            description = article['description'] if article['description'] else 'No description available'\n",
    "            location = geolocator.geocode(city)\n",
    "            print(location)\n",
    "            if location:\n",
    "                add_marker(title, description, location.latitude, location.longitude, map)\n",
    "            else:\n",
    "                print(f\"Could not geocode {city}\")\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"us_news_map.html\")\n",
    "\n",
    "print(\"Map generation complete. Check us_news_map.html for the map.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c4553de-7235-4a2e-b618-d787f47e25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map generation complete. Check us_news_map.html for the map.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "keyword = 'Donald Trump'\n",
    "base_url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map centered on USA\n",
    "map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Function to fetch news for a city\n",
    "def fetch_news(city):\n",
    "    try:\n",
    "        params = {\n",
    "            'q': keyword,\n",
    "            'apiKey': api_key,\n",
    "            'pageSize': 10,  # Fetch up to 10 articles per city\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching news for {city}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news for {city}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to add markers to the map with increased separation and randomness\n",
    "def add_markers(articles, city, map):\n",
    "    try:\n",
    "        location = geolocator.geocode(city)\n",
    "        if location:\n",
    "            for article in articles:\n",
    "                title = article['title']\n",
    "                description = article['description'] if article['description'] else 'No description available'\n",
    "                # Generate random offsets for latitude and longitude\n",
    "                lat_offset = random.uniform(-0.02, 0.02)  # Adjust the range as needed\n",
    "                lon_offset = random.uniform(-0.02, 0.02)  # Adjust the range as needed\n",
    "                folium.Marker(\n",
    "                    [location.latitude + lat_offset, location.longitude + lon_offset],\n",
    "                    popup=f\"<b>{title}</b><br>{description}\"\n",
    "                ).add_to(map)\n",
    "        else:\n",
    "            print(f\"Could not geocode {city}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding markers for {city}: {e}\")\n",
    "\n",
    "# Loop through cities and fetch news\n",
    "for city in cities:\n",
    "    news_data = fetch_news(city)\n",
    "    if news_data and news_data.get('articles'):\n",
    "        add_markers(news_data['articles'], city, map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"us_news_map.html\")\n",
    "\n",
    "print(\"Map generation complete. Check us_news_map.html for the map.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a47fc3a-6f5e-4f59-ba64-0efd2d5252fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cities  100\n",
      "City counts:\n",
      "Washington: 5 articles\n",
      "Nashville: 1 articles\n",
      "WASHINGTON: 1 articles\n",
      "Philadelphia: 1 articles\n",
      "New York: 1 articles\n",
      "Map generation complete. Check us_news_map.html for the map.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual News API key\n",
    "api_key = '6ebe77095b7445689954c1336afb6fa0'\n",
    "keyword = 'Donald Trump'\n",
    "base_url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"news_geolocator\")\n",
    "\n",
    "# Initialize map centered on USA\n",
    "map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Function to fetch news and plot locations on map\n",
    "def fetch_and_plot_news(keyword, map):\n",
    "    try:\n",
    "        params = {\n",
    "            'q': keyword,\n",
    "            'apiKey': api_key,\n",
    "            'pageSize': 100,  # Fetch up to 100 articles\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            news_data = response.json()\n",
    "            if news_data.get('articles'):\n",
    "                city_counts = {}\n",
    "                print('Total cities ',len(news_data['articles']))\n",
    "                for article in news_data['articles']:\n",
    "                    city_name = extract_city_from_article(article)\n",
    "                    if city_name:\n",
    "                        if city_name in city_counts:\n",
    "                            city_counts[city_name] += 1\n",
    "                        else:\n",
    "                            city_counts[city_name] = 1\n",
    "                        \n",
    "                        location = geolocator.geocode(city_name)\n",
    "                        if location:\n",
    "                            # Add a small random offset to the latitude and longitude\n",
    "                            lat_offset = random.uniform(-1, 1)\n",
    "                            lon_offset = random.uniform(-1, 1)\n",
    "                            \n",
    "                            folium.Marker(\n",
    "                                [location.latitude + lat_offset, location.longitude + lon_offset],\n",
    "                                popup=f\"<b>{article['title']}</b><br>{article['description']}\"\n",
    "                            ).add_to(map)\n",
    "                \n",
    "                # Print city counts\n",
    "                print(\"City counts:\")\n",
    "                for city, count in city_counts.items():\n",
    "                    print(f\"{city}: {count} articles\")\n",
    "                \n",
    "                # Check for cities with no data\n",
    "                all_cities = set(city_counts.keys())\n",
    "                cities_with_data = set(city_counts.keys())\n",
    "                cities_with_no_data = all_cities - cities_with_data\n",
    "                if cities_with_no_data:\n",
    "                    print(\"Cities with no data:\")\n",
    "                    for city in cities_with_no_data:\n",
    "                        print(city)\n",
    "            else:\n",
    "                print(\"No articles found for the keyword.\")\n",
    "        else:\n",
    "            print(f\"Error fetching news. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or plotting news: {e}\")\n",
    "\n",
    "# Function to extract city from article content\n",
    "def extract_city_from_article(article):\n",
    "    try:\n",
    "        if 'content' in article and article['content']:\n",
    "            text = article['content']\n",
    "            # Regular expression pattern to find city names\n",
    "            city_pattern = r'\\b(?:New York|Los Angeles|Chicago|Houston|Phoenix|Philadelphia|San Antonio|San Diego|Dallas|San Jose|Austin|Jacksonville|Fort Worth|Columbus|San Francisco|Charlotte|Indianapolis|Seattle|Denver|Washington|Boston|El Paso|Nashville|Detroit|Oklahoma City|Portland|Las Vegas|Memphis|Louisville|Baltimore)\\b'\n",
    "            \n",
    "            # Find all cities in the text using the pattern\n",
    "            cities_found = re.findall(city_pattern, text, flags=re.IGNORECASE)\n",
    "            \n",
    "            if cities_found:\n",
    "                # Return the first city found (you can modify as needed for your use case)\n",
    "                return cities_found[0]\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting city from article: {e}\")\n",
    "        return None\n",
    "\n",
    "# Call the function to fetch and plot news\n",
    "fetch_and_plot_news(keyword, map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"us_news_map.html\")\n",
    "\n",
    "print(\"Map generation complete. Check us_news_map.html for the map.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
