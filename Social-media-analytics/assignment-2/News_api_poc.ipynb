{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fceaf3-c0f2-466e-9f9d-409207329bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting newsapi-python\n",
      "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (2024.2.2)\n",
      "Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: newsapi-python\n",
      "Successfully installed newsapi-python-0.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f52ce60-7716-4fbb-bd08-7bd94145cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number  2\n",
      "Error fetching articles: 426 Client Error: Upgrade Required for url: https://newsapi.org/v2/everything?q=%2A&sources=bbc-news%2Cthe-verge&domains=bbc.co.uk&language=en&sort_by=relevancy&pageSize=100&page=2\n",
      "Fetched 0 articles.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to fetch news articles from NewsAPI and return a DataFrame\n",
    "def fetch_news_articles_to_dataframe(api_key):\n",
    "    endpoint = \"https://newsapi.org/v2/everything\"\n",
    "    all_articles = []\n",
    "    max_pages = 200  # Maximum number of pages to fetch\n",
    "    params = {\n",
    "        \"q\": \"*\",                                 # Query term (all)\n",
    "       \"sources\": \"bbc-news,the-verge\",  # Sources\n",
    "        \"domains\": \"bbc.co.uk\",\n",
    "        \"language\": \"en\",                         # Language\n",
    "        \"sort_by\": \"relevancy\",                   # Sort by relevancy\n",
    "        \"pageSize\": 100,                          # Number of articles per page\n",
    "        \"page\": 1                                 # Initial page\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    # Fetch articles from multiple pages\n",
    "    for page in range(2, max_pages + 1):\n",
    "        params['page'] = page\n",
    "        \n",
    "        try:\n",
    "            print(\"Page number \",page)\n",
    "            response = requests.get(endpoint, params=params, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "            # Parse JSON response\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "\n",
    "            # Append articles to the list\n",
    "            all_articles.extend(articles)\n",
    "\n",
    "            # Delay to avoid hitting rate limits\n",
    "            time.sleep(0.5)  # Adjust as necessary\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching articles: {e}\")\n",
    "            break\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_articles)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '6ebe77095b7445689954c1336afb6fa0'  # Replace with your NewsAPI API key\n",
    "    news_df = fetch_news_articles_to_dataframe(api_key)\n",
    "    \n",
    "    print(f\"Fetched {len(news_df)} articles.\")\n",
    "    \n",
    "    # Save DataFrame to CSV file\n",
    "    news_df.to_csv('news_articles.csv', index=False)\n",
    "\n",
    "    # Optionally, display or further process the DataFrame\n",
    "    # print(news_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e64bf4-0fb4-4d1d-95f8-564c8fe8050a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
