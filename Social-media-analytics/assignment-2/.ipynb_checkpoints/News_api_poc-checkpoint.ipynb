{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fceaf3-c0f2-466e-9f9d-409207329bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting newsapi-python\n",
      "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umesh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0->newsapi-python) (2024.2.2)\n",
      "Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: newsapi-python\n",
      "Successfully installed newsapi-python-0.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f52ce60-7716-4fbb-bd08-7bd94145cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number  1\n",
      "Page number  2\n",
      "Error fetching articles: 426 Client Error: Upgrade Required for url: https://newsapi.org/v2/everything?q=%2A&sources=bbc-news%2Cthe-verge%2Ccnn%2Creuters%2Cthe-guardian%2Cabc-news%2Cassociated-press%2Cbloomberg%2Cbusiness-insider%2Cbuzzfeed%2Ccbc-news%2Ccbs-news%2Cengadget%2Cespn%2Cfortune%2Cfox-news%2Cgoogle-news%2Cindependent%2Cnbc-news%2Cnew-scientist%2Cnew-york-magazine%2Ctechcrunch%2Cthe-huffington-post%2Cthe-wall-street-journal%2Cthe-washington-post%2Ctime%2Cusa-today&domains=bbc.co.uk%2Ctechcrunch.com%2Ccnn.com%2Creuters.com%2Ctheguardian.com%2Cabcnews.go.com%2Capnews.com%2Cbloomberg.com%2Cbusinessinsider.com%2Cbuzzfeed.com%2Ccbc.ca%2Ccbsnews.com%2Cengadget.com%2Cespn.com%2Cfortune.com%2Cfoxnews.com%2Cnews.google.com%2Cindependent.co.uk%2Cnbcnews.com%2Cnewscientist.com%2Cnymag.com%2Ctechcrunch.com%2Chuffpost.com%2Cwsj.com%2Cwashingtonpost.com%2Ctime.com%2Cusatoday.com&language=en&sort_by=relevancy&pageSize=100&page=2\n",
      "Fetched 100 articles.\n",
      "                              source author      title description  \\\n",
      "0  {'id': None, 'name': '[Removed]'}   None  [Removed]   [Removed]   \n",
      "1  {'id': None, 'name': '[Removed]'}   None  [Removed]   [Removed]   \n",
      "2  {'id': None, 'name': '[Removed]'}   None  [Removed]   [Removed]   \n",
      "3  {'id': None, 'name': '[Removed]'}   None  [Removed]   [Removed]   \n",
      "4  {'id': None, 'name': '[Removed]'}   None  [Removed]   [Removed]   \n",
      "\n",
      "                   url urlToImage           publishedAt    content  \n",
      "0  https://removed.com       None  1970-01-01T00:00:00Z  [Removed]  \n",
      "1  https://removed.com       None  1970-01-01T00:00:00Z  [Removed]  \n",
      "2  https://removed.com       None  1970-01-01T00:00:00Z  [Removed]  \n",
      "3  https://removed.com       None  1970-01-01T00:00:00Z  [Removed]  \n",
      "4  https://removed.com       None  1970-01-01T00:00:00Z  [Removed]  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to fetch news articles from NewsAPI and return a DataFrame\n",
    "def fetch_news_articles_to_dataframe(api_key):\n",
    "    endpoint = \"https://newsapi.org/v2/everything\"\n",
    "    all_articles = []\n",
    "    max_pages = 200  # Maximum number of pages to fetch\n",
    "    params = {\n",
    "        \"q\": \"*\",                                 # Query term (all)\n",
    "       \"sources\": \"bbc-news,the-verge,cnn,reuters,the-guardian,abc-news,associated-press,bloomberg,business-insider,buzzfeed,cbc-news,cbs-news,engadget,espn,fortune,fox-news,google-news,independent,nbc-news,new-scientist,new-york-magazine,techcrunch,the-huffington-post,the-wall-street-journal,the-washington-post,time,usa-today\",  # Sources\n",
    "        \"domains\": \"bbc.co.uk,techcrunch.com,cnn.com,reuters.com,theguardian.com,abcnews.go.com,apnews.com,bloomberg.com,businessinsider.com,buzzfeed.com,cbc.ca,cbsnews.com,engadget.com,espn.com,fortune.com,foxnews.com,news.google.com,independent.co.uk,nbcnews.com,newscientist.com,nymag.com,techcrunch.com,huffpost.com,wsj.com,washingtonpost.com,time.com,usatoday.com\", # Domains\n",
    "        \"language\": \"en\",                         # Language\n",
    "        \"sort_by\": \"relevancy\",                   # Sort by relevancy\n",
    "        \"pageSize\": 100,                          # Number of articles per page\n",
    "        \"page\": 1                                 # Initial page\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    # Fetch articles from multiple pages\n",
    "    for page in range(1, max_pages + 1):\n",
    "        params['page'] = page\n",
    "        \n",
    "        try:\n",
    "            print(\"Page number \",page)\n",
    "            response = requests.get(endpoint, params=params, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "            # Parse JSON response\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "\n",
    "            # Append articles to the list\n",
    "            all_articles.extend(articles)\n",
    "\n",
    "            # Delay to avoid hitting rate limits\n",
    "            time.sleep(0.5)  # Adjust as necessary\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching articles: {e}\")\n",
    "            break\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_articles)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '6ebe77095b7445689954c1336afb6fa0'  # Replace with your NewsAPI API key\n",
    "    news_df = fetch_news_articles_to_dataframe(api_key)\n",
    "    \n",
    "    print(f\"Fetched {len(news_df)} articles.\")\n",
    "    \n",
    "    # Save DataFrame to CSV file\n",
    "    news_df.to_csv('news_articles.csv', index=False)\n",
    "\n",
    "    # Optionally, display or further process the DataFrame\n",
    "    # print(news_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e64bf4-0fb4-4d1d-95f8-564c8fe8050a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
